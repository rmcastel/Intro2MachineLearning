{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as sm\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import statsmodels.api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto=pd.read_csv('./data/Auto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=auto.sample(n=196, random_state=2)\n",
    "test=auto[~auto.index.isin(train.index)]\n",
    "#df[~df.index.isin(boot.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Validation Set Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_1=sm.ols('mpg~horsepower', data=train)\n",
    "lm_1_mod=lm_1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1=lm_1_mod.predict(test['horsepower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model MSE: 25.11\n"
     ]
    }
   ],
   "source": [
    "print(f'Linear Model MSE: {mean_squared_error(test[\"mpg\"], pred_1):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm=sm.ols('mpg~horsepower+I(horsepower**2)', data=train)\n",
    "qm_mod=qm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic Model MSE: 19.72\n"
     ]
    }
   ],
   "source": [
    "qm_pred=qm_mod.predict(test['horsepower'])\n",
    "print(f'Quadratic Model MSE: {mean_squared_error(test[\"mpg\"], qm_pred):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cubic Model MSE: 19.92\n"
     ]
    }
   ],
   "source": [
    "qm=sm.ols('mpg~horsepower+I(horsepower**2)+I(horsepower**3)', data=train)\n",
    "qm_mod=qm.fit()\n",
    "\n",
    "qm_pred=qm_mod.predict(test['horsepower'])\n",
    "print(f'Cubic Model MSE: {mean_squared_error(test[\"mpg\"], qm_pred):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-One-Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richy\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X=statsmodels.api.add_constant(auto['horsepower'])\n",
    "y=auto['mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(mean_squared_error)\n",
    "model=LinearRegression()\n",
    "\n",
    "LOO=cross_val_score(model, X=X, y=y, cv=X.shape[0], scoring=scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.231513517929226"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOO.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo_means=[]\n",
    "for order in range(1, 6):\n",
    "    poly = PolynomialFeatures(degree=order,interaction_only=False, include_bias=False)\n",
    "    \n",
    "    model=LinearRegression()\n",
    "    LOO_raised=cross_val_score(model, X=poly.fit_transform(X), y=y, cv=X.shape[0], scoring=scorer)\n",
    "    \n",
    "    loo_means.append(LOO_raised.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24.231513517929226,\n",
       " 19.24821312448975,\n",
       " 19.334984064043173,\n",
       " 19.424430310361764,\n",
       " 19.03321358686367]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loo_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_cv_means=[]\n",
    "for order in range(1, 11):\n",
    "    poly = PolynomialFeatures(degree=order,interaction_only=False, include_bias=False)\n",
    "    \n",
    "    model=LinearRegression()\n",
    "    kf_cv_raised=cross_val_score(model, X=poly.fit_transform(X), y=y, cv=10, scoring=scorer)\n",
    "    \n",
    "    kf_cv_means.append(kf_cv_raised.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27.439933652339857,\n",
       " 21.235840055802306,\n",
       " 21.336606183191904,\n",
       " 21.353886980908165,\n",
       " 20.905643195478888,\n",
       " 20.784472952501865,\n",
       " 20.880627227790693,\n",
       " 21.07858300938988,\n",
       " 21.042177187755662,\n",
       " 21.027618772515318]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf_cv_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training indices: 352\n",
      "Number of validation indices: 40\n",
      "Number of training indices: 352\n",
      "Number of validation indices: 40\n",
      "Number of training indices: 353\n",
      "Number of validation indices: 39\n",
      "Number of training indices: 353\n",
      "Number of validation indices: 39\n",
      "Number of training indices: 353\n",
      "Number of validation indices: 39\n",
      "Number of training indices: 353\n",
      "Number of validation indices: 39\n",
      "Number of training indices: 353\n",
      "Number of validation indices: 39\n",
      "Number of training indices: 353\n",
      "Number of validation indices: 39\n",
      "Number of training indices: 353\n",
      "Number of validation indices: 39\n",
      "Number of training indices: 353\n",
      "Number of validation indices: 39\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Use KFold\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1111)\n",
    "\n",
    "# Create splits\n",
    "splits = kf.split(X)\n",
    "\n",
    "# Print the number of indices\n",
    "for train_index, val_index in splits:\n",
    "    print(\"Number of training indices: %s\" % len(train_index))\n",
    "    print(\"Number of validation indices: %s\" % len(val_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=auto['horsepower']\n",
    "y=auto['mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split accuracy: 25.340509269972657\n",
      "Split accuracy: 20.769461355335974\n",
      "Split accuracy: 27.341704864673027\n",
      "Split accuracy: 28.10105011712353\n",
      "Split accuracy: 15.933777254563257\n",
      "Split accuracy: 39.79714781695028"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richy\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\Users\\Richy\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\Users\\Richy\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\Users\\Richy\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\Users\\Richy\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\Users\\Richy\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\Users\\Richy\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\Users\\Richy\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split accuracy: 16.901207197517344\n",
      "Split accuracy: 28.56239675581579\n",
      "Split accuracy: 17.780969177207037\n",
      "Split accuracy: 21.29513514653329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richy\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\Users\\Richy\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Use KFold\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=17)\n",
    "\n",
    "# Create splits\n",
    "splits = kf.split(X)\n",
    "\n",
    "kF_CV_means=[]\n",
    "LR=LinearRegression()\n",
    "\n",
    "# Access the training and validation indices of splits\n",
    "for train_index, val_index in splits:\n",
    "    # Setup the training and validation data\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_val, y_val = X[val_index], y[val_index]\n",
    "    \n",
    "    #Add constant column\n",
    "    X_train=statsmodels.api.add_constant(X_train)\n",
    "    X_val=statsmodels.api.add_constant(X_val)\n",
    "    \n",
    "    # Fit the Linear Regression model\n",
    "    LR.fit(X_train, y_train)\n",
    "    # Make predictions, and print the accuracy\n",
    "    predictions = LR.predict(X_val)\n",
    "    kF_CV_means.append(predictions)\n",
    "    print(\"Split accuracy: \" + str(mean_squared_error(y_val, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27.439933652339857,\n",
       " 21.235840055802306,\n",
       " 21.336606183191904,\n",
       " 21.353886980908165,\n",
       " 20.905643195478888,\n",
       " 20.784472952501865,\n",
       " 20.880627227790693,\n",
       " 21.07858300938988,\n",
       " 21.042177187755662,\n",
       " 21.027618772515318]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf_cv_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "port=pd.read_csv('./data/Portfolio.csv', ).drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(data, num_samples=100):\n",
    "    indices = np.random.choice(data.index, num_samples, replace=True)\n",
    "    \n",
    "    X=data['X'][indices]\n",
    "    Y=data['Y'][indices]\n",
    "\n",
    "    return (np.var(Y) - np.cov(X,Y)[0][1])/(np.var(X) + np.var(Y) - 2*np.cov(X,Y)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5603366580074973"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "alpha(port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "samps=1000\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_mean=np.array([])\n",
    "for i in range(samps):\n",
    "    #np.random.seed(i)\n",
    "    cov=alpha(port)\n",
    "    \n",
    "    boot_mean=np.append(boot_mean, cov)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56033666, 0.65174607, 0.6419836 , 0.5265089 , 0.61294813,\n",
       "       0.52209904, 0.46775   , 0.75344004, 0.51743963, 0.34067531,\n",
       "       0.55467457, 0.50726371, 0.45677697, 0.84232309, 0.51437895,\n",
       "       0.58053411, 0.55137652, 0.61623751, 0.6564123 , 0.45009759,\n",
       "       0.412622  , 0.48617674, 0.61685721, 0.63181173, 0.5070456 ,\n",
       "       0.53658192, 0.53840006, 0.61253538, 0.47590297, 0.56768259,\n",
       "       0.59664443, 0.44780639, 0.59371197, 0.53292039, 0.55115268,\n",
       "       0.67859663, 0.56698495, 0.52392205, 0.49284052, 0.57410441,\n",
       "       0.54972   , 0.44702787, 0.58108487, 0.62142922, 0.65780197,\n",
       "       0.53654144, 0.66946174, 0.40557907, 0.69823427, 0.57634229,\n",
       "       0.61499109, 0.6551613 , 0.57530644, 0.65694267, 0.48974632,\n",
       "       0.56829308, 0.56281435, 0.53854187, 0.48431801, 0.67552819,\n",
       "       0.54836828, 0.76162708, 0.60517566, 0.82613741, 0.54471018,\n",
       "       0.71617603, 0.52345425, 0.68945531, 0.47532653, 0.55894233,\n",
       "       0.5041125 , 0.46425938, 0.53494607, 0.77037703, 0.57043772,\n",
       "       0.63385737, 0.56299395, 0.50406251, 0.62254076, 0.62294676,\n",
       "       0.83087751, 0.57382992, 0.62780662, 0.63326325, 0.63578443,\n",
       "       0.59959668, 0.62098452, 0.49068886, 0.46015517, 0.69246475,\n",
       "       0.47026963, 0.47903848, 0.45802724, 0.51110809, 0.56179436,\n",
       "       0.75500412, 0.45244864, 0.72210753, 0.49795655, 0.55824899,\n",
       "       0.61017347, 0.60667016, 0.53264786, 0.45242889, 0.65948059,\n",
       "       0.48861609, 0.53630907, 0.59955539, 0.57017002, 0.56498622,\n",
       "       0.65923506, 0.62388668, 0.72969348, 0.53460307, 0.60837791,\n",
       "       0.65645671, 0.76037281, 0.49117777, 0.66752421, 0.7146463 ,\n",
       "       0.56529355, 0.47004116, 0.54312358, 0.61765002, 0.46457496,\n",
       "       0.56234682, 0.57043533, 0.71489291, 0.508335  , 0.57724269,\n",
       "       0.49497234, 0.55313172, 0.60193803, 0.35804977, 0.62229287,\n",
       "       0.59038312, 0.54938003, 0.72079017, 0.52841721, 0.83051389,\n",
       "       0.73494391, 0.49057866, 0.62740145, 0.70790818, 0.63478608,\n",
       "       0.51090083, 0.35113581, 0.56103796, 0.58848179, 0.58818969,\n",
       "       0.59119972, 0.56880589, 0.46520321, 0.59026857, 0.53380123,\n",
       "       0.72107305, 0.69317482, 0.61185604, 0.57322983, 0.45293478,\n",
       "       0.68100445, 0.56580936, 0.67923225, 0.50586248, 0.50747116,\n",
       "       0.59841595, 0.47621937, 0.50144194, 0.57713445, 0.62407593,\n",
       "       0.64061768, 0.80030838, 0.61885128, 0.55617148, 0.60294751,\n",
       "       0.48623051, 0.52882955, 0.44986826, 0.58357903, 0.70449696,\n",
       "       0.40413094, 0.5470326 , 0.50733017, 0.65518312, 0.69748406,\n",
       "       0.62007283, 0.60044722, 0.57329041, 0.53926609, 0.68129481,\n",
       "       0.5519339 , 0.49140104, 0.5678841 , 0.67537048, 0.58375277,\n",
       "       0.45111905, 0.53282567, 0.68386081, 0.45779143, 0.51660471,\n",
       "       0.46372758, 0.70293781, 0.5891807 , 0.66755188, 0.56716735,\n",
       "       0.60780278, 0.55405848, 0.54369449, 0.57016157, 0.52107178,\n",
       "       0.61518438, 0.71965829, 0.4421088 , 0.66917448, 0.69866473,\n",
       "       0.65127855, 0.73343991, 0.48727157, 0.51654302, 0.58578537,\n",
       "       0.73965501, 0.61938248, 0.62080488, 0.61391427, 0.57874317,\n",
       "       0.58363153, 0.49154926, 0.60252575, 0.5168071 , 0.52531985,\n",
       "       0.52429956, 0.61213014, 0.55707514, 0.61082817, 0.61927857,\n",
       "       0.51866443, 0.61548763, 0.67492131, 0.66135384, 0.53959252,\n",
       "       0.64775357, 0.5723726 , 0.60595538, 0.49287725, 0.50435641,\n",
       "       0.61618958, 0.60713377, 0.59274661, 0.65062323, 0.6051339 ,\n",
       "       0.56261148, 0.6843801 , 0.62927458, 0.57915229, 0.67193971,\n",
       "       0.52949043, 0.76222955, 0.64682256, 0.57702278, 0.52580868,\n",
       "       0.5901242 , 0.5666967 , 0.74129668, 0.67089559, 0.41076428,\n",
       "       0.55494009, 0.60621491, 0.71980153, 0.67117167, 0.55246857,\n",
       "       0.59425497, 0.90772828, 0.66774535, 0.54620205, 0.42452808,\n",
       "       0.70205954, 0.68936666, 0.56478463, 0.73050442, 0.52376425,\n",
       "       0.55230822, 0.65321714, 0.5364886 , 0.4971967 , 0.4627546 ,\n",
       "       0.51324538, 0.63484858, 0.64350307, 0.66834867, 0.86926971,\n",
       "       0.41643469, 0.74193909, 0.59700886, 0.61237542, 0.64596691,\n",
       "       0.56796579, 0.61302623, 0.51595052, 0.47816877, 0.57881749,\n",
       "       0.517206  , 0.39868489, 0.69497393, 0.56520906, 0.53087474,\n",
       "       0.59813381, 0.69386852, 0.66130712, 0.73791011, 0.61039461,\n",
       "       0.58043964, 0.52548855, 0.58132219, 0.54072825, 0.80871131,\n",
       "       0.47344997, 0.74943369, 0.61016201, 0.57229385, 0.75786361,\n",
       "       0.61975797, 0.67386731, 0.70225113, 0.45573749, 0.63875123,\n",
       "       0.44628654, 0.56545615, 0.66304771, 0.62594779, 0.48139525,\n",
       "       0.59822332, 0.57841261, 0.61586336, 0.60786273, 0.51754938,\n",
       "       0.54538802, 0.50474036, 0.58660068, 0.59806342, 0.39036504,\n",
       "       0.74685378, 0.57088772, 0.6047654 , 0.53882118, 0.48638124,\n",
       "       0.60530408, 0.55607065, 0.67848139, 0.60894325, 0.78254857,\n",
       "       0.55682231, 0.64609169, 0.61066489, 0.60259191, 0.79348866,\n",
       "       0.63556819, 0.47334678, 0.61866284, 0.59480501, 0.69593798,\n",
       "       0.52883169, 0.54907531, 0.5742473 , 0.68192222, 0.63544199,\n",
       "       0.61906422, 0.5271771 , 0.55424439, 0.71402399, 0.56432557,\n",
       "       0.47413326, 0.67506227, 0.61760048, 0.47241201, 0.53293344,\n",
       "       0.63619621, 0.55023214, 0.85568985, 0.47561696, 0.70073429,\n",
       "       0.61612844, 0.54626737, 0.71042522, 0.52022206, 0.66729066,\n",
       "       0.49453318, 0.52240108, 0.49045514, 0.68833608, 0.57616463,\n",
       "       0.45586229, 0.69061871, 0.58088568, 0.60347947, 0.76372476,\n",
       "       0.76275012, 0.46118479, 0.56769987, 0.71192275, 0.43352175,\n",
       "       0.75264094, 0.56739825, 0.48146907, 0.57160839, 0.47894269,\n",
       "       0.48965848, 0.4910886 , 0.58608943, 0.55483738, 0.61807543,\n",
       "       0.69472771, 0.67297176, 0.55767545, 0.55690019, 0.53761711,\n",
       "       0.61022739, 0.6229693 , 0.53245148, 0.60515725, 0.73798261,\n",
       "       0.55790869, 0.49886584, 0.57082844, 0.55750791, 0.66989408,\n",
       "       0.57009327, 0.60576441, 0.44242338, 0.5398248 , 0.6202067 ,\n",
       "       0.49785459, 0.62848607, 0.44497284, 0.63334052, 0.62830865,\n",
       "       0.70750162, 0.64737034, 0.62314844, 0.61831854, 0.60268372,\n",
       "       0.4331945 , 0.65571307, 0.72777922, 0.54723488, 0.51390271,\n",
       "       0.44361672, 0.68392842, 0.6173822 , 0.56539324, 0.62176342,\n",
       "       0.55644336, 0.60884597, 0.4987222 , 0.69078818, 0.63968118,\n",
       "       0.58275948, 0.62200138, 0.54313994, 0.51688798, 0.53852613,\n",
       "       0.54056738, 0.65508245, 0.78374143, 0.60552207, 0.5642404 ,\n",
       "       0.57912562, 0.56862058, 0.48669725, 0.65070175, 0.62384361,\n",
       "       0.52099772, 0.60549663, 0.56463951, 0.68591479, 0.45592836,\n",
       "       0.59389822, 0.48657104, 0.44280568, 0.67799302, 0.65941415,\n",
       "       0.59123429, 0.52239295, 0.67876049, 0.6067934 , 0.51208534,\n",
       "       0.55515854, 0.53738862, 0.57984724, 0.50231933, 0.46155803,\n",
       "       0.48161882, 0.60321682, 0.58344043, 0.60968627, 0.66816509,\n",
       "       0.65866862, 0.69949188, 0.50007003, 0.63270282, 0.65365838,\n",
       "       0.56388672, 0.56714547, 0.79074385, 0.4768877 , 0.67690648,\n",
       "       0.64835256, 0.47095481, 0.45560433, 0.49762515, 0.54685354,\n",
       "       0.49073571, 0.43034332, 0.37592355, 0.61952258, 0.60354434,\n",
       "       0.52587249, 0.5760088 , 0.61642109, 0.45678026, 0.51852257,\n",
       "       0.73189784, 0.5923745 , 0.59037867, 0.65863886, 0.43828053,\n",
       "       0.47312515, 0.69393594, 0.55909012, 0.44362089, 0.47692519,\n",
       "       0.49434432, 0.46694512, 0.57110275, 0.58210516, 0.54695977,\n",
       "       0.7247901 , 0.50156439, 0.78798521, 0.52312614, 0.54726947,\n",
       "       0.63634021, 0.50807834, 0.54903106, 0.49248046, 0.57585753,\n",
       "       0.73402896, 0.54958254, 0.52079233, 0.68191433, 0.47417537,\n",
       "       0.61283521, 0.68523883, 0.50314232, 0.59095995, 0.51838393,\n",
       "       0.48728495, 0.74479524, 0.49960261, 0.68108029, 0.5546512 ,\n",
       "       0.45934713, 0.57391166, 0.60034082, 0.6422681 , 0.64339874,\n",
       "       0.65155104, 0.48166399, 0.60581216, 0.68502232, 0.47246952,\n",
       "       0.64278325, 0.56577411, 0.79278255, 0.52700311, 0.53833425,\n",
       "       0.54672368, 0.61441745, 0.59802438, 0.6483518 , 0.63504497,\n",
       "       0.42444257, 0.58776642, 0.6277792 , 0.65508978, 0.53986301,\n",
       "       0.5192574 , 0.51695631, 0.59657605, 0.57387222, 0.58226716,\n",
       "       0.4513669 , 0.6931107 , 0.72502871, 0.49264396, 0.47576679,\n",
       "       0.53341393, 0.53940342, 0.66261137, 0.61011931, 0.60134847,\n",
       "       0.54092198, 0.39824875, 0.59955887, 0.65992166, 0.59103858,\n",
       "       0.54450805, 0.46617899, 0.50721969, 0.75590692, 0.42073673,\n",
       "       0.51369167, 0.57097925, 0.64133402, 0.60167148, 0.60064735,\n",
       "       0.64482932, 0.47331813, 0.57071525, 0.44395436, 0.51045771,\n",
       "       0.72151401, 0.50258432, 0.54971727, 0.47349504, 0.53689335,\n",
       "       0.48264994, 0.54226851, 0.6418742 , 0.69032407, 0.73435947,\n",
       "       0.57704356, 0.48811668, 0.67606308, 0.61016475, 0.51114209,\n",
       "       0.61234475, 0.5209561 , 0.63490691, 0.62223432, 0.496911  ,\n",
       "       0.50207496, 0.6393343 , 0.76261313, 0.49887959, 0.51392906,\n",
       "       0.6960111 , 0.53214569, 0.59250112, 0.63721063, 0.45916667,\n",
       "       0.6901323 , 0.52389114, 0.4840207 , 0.72207333, 0.56678801,\n",
       "       0.70457824, 0.5192226 , 0.51350885, 0.62308146, 0.44066702,\n",
       "       0.52601672, 0.69342414, 0.60036095, 0.60855582, 0.58586283,\n",
       "       0.52173815, 0.58454561, 0.64224671, 0.63663519, 0.57071034,\n",
       "       0.7707465 , 0.5859499 , 0.6178166 , 0.49600186, 0.61397363,\n",
       "       0.63882891, 0.479566  , 0.54167364, 0.51037392, 0.65765573,\n",
       "       0.47467487, 0.3649107 , 0.55059966, 0.69978607, 0.64581064,\n",
       "       0.69534375, 0.71128408, 0.54818527, 0.65181029, 0.73629207,\n",
       "       0.68102455, 0.46839857, 0.67399701, 0.53697828, 0.72254354,\n",
       "       0.48617428, 0.67491765, 0.48899534, 0.67121862, 0.64888071,\n",
       "       0.40254739, 0.74547803, 0.58325905, 0.68192733, 0.46014621,\n",
       "       0.69507075, 0.56050244, 0.72511051, 0.52515354, 0.58991588,\n",
       "       0.65297858, 0.50719669, 0.64480821, 0.69437572, 0.45286952,\n",
       "       0.55325207, 0.73078134, 0.64274818, 0.4419448 , 0.67048337,\n",
       "       0.49543787, 0.51293289, 0.44587098, 0.70653332, 0.46674193,\n",
       "       0.63701369, 0.58741511, 0.46988689, 0.61428193, 0.617486  ,\n",
       "       0.59931243, 0.38381529, 0.61222182, 0.77071355, 0.53846988,\n",
       "       0.58734491, 0.64668248, 0.4922649 , 0.47374827, 0.45626667,\n",
       "       0.52499741, 0.42726478, 0.55670704, 0.53643707, 0.49911155,\n",
       "       0.5617134 , 0.65727788, 0.60254372, 0.46750214, 0.58754673,\n",
       "       0.64161912, 0.47006583, 0.45658624, 0.67979415, 0.52639266,\n",
       "       0.54484429, 0.62242994, 0.36143654, 0.66062766, 0.47653032,\n",
       "       0.51825961, 0.49195472, 0.51990121, 0.63139866, 0.71462787,\n",
       "       0.63350947, 0.56849002, 0.40646122, 0.5478017 , 0.52343622,\n",
       "       0.69500233, 0.5070108 , 0.49141776, 0.44269007, 0.51515285,\n",
       "       0.7184197 , 0.4965705 , 0.67693833, 0.72843287, 0.56519486,\n",
       "       0.81448024, 0.55311037, 0.62208388, 0.61314279, 0.53143561,\n",
       "       0.50190047, 0.68787761, 0.51984791, 0.69377498, 0.79968731,\n",
       "       0.53743581, 0.46028489, 0.61864205, 0.48331013, 0.42551633,\n",
       "       0.49759335, 0.62897427, 0.46958453, 0.5396312 , 0.57899541,\n",
       "       0.59419738, 0.50369907, 0.45149333, 0.54924281, 0.77684914,\n",
       "       0.55240061, 0.565964  , 0.46742102, 0.61151022, 0.62578165,\n",
       "       0.58445711, 0.49498051, 0.60130272, 0.43492779, 0.61753563,\n",
       "       0.61575681, 0.62470256, 0.65902659, 0.51265604, 0.54800743,\n",
       "       0.66629201, 0.64878094, 0.46170215, 0.50525864, 0.58243479,\n",
       "       0.59237177, 0.55381211, 0.66908886, 0.80386093, 0.61934539,\n",
       "       0.57558668, 0.6006284 , 0.56107011, 0.56941132, 0.5958089 ,\n",
       "       0.63109092, 0.62027125, 0.48437865, 0.50311496, 0.44780736,\n",
       "       0.47818013, 0.56806705, 0.61956386, 0.56709678, 0.60715929,\n",
       "       0.53053391, 0.6916127 , 0.47144546, 0.57537952, 0.48689561,\n",
       "       0.57743845, 0.44881672, 0.48588825, 0.76160855, 0.4837288 ,\n",
       "       0.56438258, 0.57403242, 0.55679833, 0.44892728, 0.57882673,\n",
       "       0.5349986 , 0.52702459, 0.57233565, 0.73970111, 0.61326412,\n",
       "       0.57244091, 0.39425914, 0.51312469, 0.63442422, 0.67758919,\n",
       "       0.44888825, 0.73726389, 0.5842689 , 0.57355045, 0.76818192,\n",
       "       0.58266708, 0.49086102, 0.58917768, 0.4998773 , 0.52576936,\n",
       "       0.6022464 , 0.4678069 , 0.5266401 , 0.62637092, 0.56169104,\n",
       "       0.50431202, 0.44148462, 0.49759851, 0.56169693, 0.6503479 ,\n",
       "       0.46314055, 0.53300396, 0.63449413, 0.62462585, 0.65454246,\n",
       "       0.58141048, 0.64405929, 0.60879696, 0.47891618, 0.68319117,\n",
       "       0.68504636, 0.5465234 , 0.69942275, 0.66421728, 0.78514785,\n",
       "       0.5052038 , 0.55081157, 0.48591185, 0.60307133, 0.5930599 ,\n",
       "       0.62463035, 0.45138533, 0.63300752, 0.43160431, 0.64352918,\n",
       "       0.42846399, 0.68498086, 0.62626881, 0.51346957, 0.56014504,\n",
       "       0.55331406, 0.44531462, 0.7533517 , 0.53701852, 0.40263202,\n",
       "       0.56363932, 0.50328667, 0.48026859, 0.57076155, 0.46900218,\n",
       "       0.58162094, 0.53961075, 0.59874587, 0.65870228, 0.4239967 ,\n",
       "       0.44538256, 0.47001908, 0.5935951 , 0.68947567, 0.61302828,\n",
       "       0.63830121, 0.52807665, 0.47591806, 0.52899215, 0.63982147,\n",
       "       0.58604759, 0.53113261, 0.51339779, 0.56155469, 0.44935253,\n",
       "       0.46468349, 0.75867418, 0.70258958, 0.59987098, 0.70666355,\n",
       "       0.64075842, 0.62335697, 0.51876532, 0.70645524, 0.4481494 ,\n",
       "       0.57301684, 0.64559208, 0.37269114, 0.44784588, 0.47615657,\n",
       "       0.52829219, 0.51612856, 0.50846691, 0.52570202, 0.56297318,\n",
       "       0.58272858, 0.63661058, 0.6765333 , 0.64650559, 0.55600844,\n",
       "       0.75761211, 0.65640336, 0.49686207, 0.52007875, 0.47279004,\n",
       "       0.68649964, 0.6228845 , 0.55254606, 0.52528127, 0.61226666,\n",
       "       0.61210632, 0.62997575, 0.5414613 , 0.52213182, 0.3846283 ,\n",
       "       0.58817287, 0.58990553, 0.70751706, 0.65878889, 0.49117251,\n",
       "       0.62507495, 0.56466299, 0.54035123, 0.63200768, 0.66818282])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Statistics:\n",
      "Mean Alpha: 0.5806\n",
      "Std. Error: 0.0898\n"
     ]
    }
   ],
   "source": [
    "print(f'Bootstrap Statistics:\\n\\\n",
    "Mean Alpha: {boot_mean.mean():.4}\\n\\\n",
    "Std. Error: {boot_mean.std():.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=auto.sample(n=len(auto.index), replace=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM=sm.ols('mpg~horsepower', data=data).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.599\n",
      "Model:                            OLS   Adj. R-squared:                  0.598\n",
      "Method:                 Least Squares   F-statistic:                     581.8\n",
      "Date:                Wed, 29 Apr 2020   Prob (F-statistic):           2.52e-79\n",
      "Time:                        16:10:56   Log-Likelihood:                -1174.0\n",
      "No. Observations:                 392   AIC:                             2352.\n",
      "Df Residuals:                     390   BIC:                             2360.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     39.6585      0.714     55.575      0.000      38.255      41.061\n",
      "horsepower    -0.1559      0.006    -24.120      0.000      -0.169      -0.143\n",
      "==============================================================================\n",
      "Omnibus:                       17.579   Durbin-Watson:                   2.046\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               19.965\n",
      "Skew:                           0.450   Prob(JB):                     4.62e-05\n",
      "Kurtosis:                       3.643   Cond. No.                         322.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(LM.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 39.66\n",
      "horsepower: -0.1559\n"
     ]
    }
   ],
   "source": [
    "params=LM.params\n",
    "print(f'Intercept: {params[0]:.4}\\nhorsepower: {params[1]:.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will Get Different Outcomes Depending On Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 40.45\n",
      "horsepower: -0.1614\n"
     ]
    }
   ],
   "source": [
    "data=auto.sample(n=len(auto.index), replace=True, random_state=10)\n",
    "LM=sm.ols('mpg~horsepower', data=data).fit()\n",
    "params=LM.params\n",
    "print(f'Intercept: {params[0]:.4}\\nhorsepower: {params[1]:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_means=[]\n",
    "horses_means=[]\n",
    "\n",
    "inter_std=[]\n",
    "horses_std=[]\n",
    "boots=1000\n",
    "for i in range(boots):\n",
    "    data=auto.sample(n=len(auto.index), replace=True, random_state=1)\n",
    "    LM=sm.ols('mpg~horsepower', data=data).fit()\n",
    "    \n",
    "    inter_means.append(LM.params[0])\n",
    "    horses_means.append(LM.params[1])\n",
    "    \n",
    "    inter_std.append(LM.bse[0])\n",
    "    horses_std.append(LM.bse[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 39.66    Std. Error: 0.7136\n",
      "horsepower: -0.1559    Std. Error: 0.006464\n"
     ]
    }
   ],
   "source": [
    "print(f'Intercept: {np.mean(inter_means):.4}    Std. Error: {np.mean(inter_std):.4}\\nhorsepower: {np.mean(horses_means):.4}    Std. Error: {np.mean(horses_std):.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     39.658479\n",
       "horsepower    -0.155898\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     0.713597\n",
       "horsepower    0.006464\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM.bse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_means=[]\n",
    "horses_means=[]\n",
    "horses2_means=[]\n",
    "\n",
    "inter_std=[]\n",
    "horses_std=[]\n",
    "horses2_std=[]\n",
    "boots=1000\n",
    "for i in range(boots):\n",
    "    data=auto.sample(n=len(auto.index), replace=True, random_state=1)\n",
    "    LM=sm.ols('mpg~horsepower+I(horsepower**2)', data=data).fit()\n",
    "    \n",
    "    inter_means.append(LM.params[0])\n",
    "    horses_means.append(LM.params[1])\n",
    "    horses2_means.append(LM.params[2])\n",
    "    \n",
    "    inter_std.append(LM.bse[0])\n",
    "    horses_std.append(LM.bse[1])\n",
    "    horses2_std.append(LM.bse[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 57.59    Std. Error: 1.802\n",
      "horsepower: -0.4776    Std. Error: 0.03082\n",
      "horsepower^2: 0.001266    Std. Error: 0.0001192\n"
     ]
    }
   ],
   "source": [
    "print(f'Intercept: {np.mean(inter_means):.4}    Std. Error: {np.mean(inter_std):.4}\\n\\\n",
    "horsepower: {np.mean(horses_means):.4}    Std. Error: {np.mean(horses_std):.4}\\n\\\n",
    "horsepower^2: {np.mean(horses2_means):.4}    Std. Error: {np.mean(horses2_std):.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
